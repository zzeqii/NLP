{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zixu9636_Lab07.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "rFBFgEEkIaQ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab 07 Dependency parsing\n"
      ]
    },
    {
      "metadata": {
        "id": "bJkHSIOyIpUh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependency Parsing Exercise\n",
        "\n",
        "Let's parse the following sentences! (Use your skill that you learned in the lecture)\n",
        "\n",
        "\n",
        "*  John lives in New York\n",
        "*  Mark Watney visited Mars\n",
        "*  I prefer the morning flight through Denver\n",
        "\n",
        "\n",
        "Do this parsing exercise with your tutor and ***check with the answer (the end of this lab07 material)***\n"
      ]
    },
    {
      "metadata": {
        "id": "Nlu9so31PX7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dependency parsing process:** (Need more detailed parsing step? Please watch the lecture 7 recording!)\n",
        "\n",
        "You can start the parsing with finding the predicate. For example, the head of token 'John' is token 'lives', because 'John' is the suject object of the predicate 'lives'. The head of 'live' is a fake token 'ROOT', we do this just for simplificity that every sentence has a same root node, which is the head of the entire structure"
      ]
    },
    {
      "metadata": {
        "id": "dK4z5pWkQEMe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Off-the-Shelf Tool (Spacy Parser)\n",
        "Now let's use [spaCy](https://spacy.io/) to automatically parse sentences.\n",
        "The spacy parser was developed based on the neural network based parser.\n",
        "\n",
        "Parse the sentence ***'The woman showed a wellshaped smile in the dark.'***\n"
      ]
    },
    {
      "metadata": {
        "id": "LBrzHpnzIBrl",
        "colab_type": "code",
        "outputId": "b1015a98-605f-4f6c-c318-aa9d02f1fabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "#PrettyTable is a Python library for generating simple ASCII tables.\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "#load the spacy api with the pre-trained statistical models for English. English multi-task CNN trained on OntoNotes\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#define the sentence\n",
        "sentence = \"The woman showed a wellshaped smile in the dark.\"\n",
        "parse = nlp(sentence)\n",
        "\n",
        "\n",
        "x = PrettyTable()\n",
        "#define column names\n",
        "x.field_names = [\"TokenID\", \"Token\", \"HeadID\", \"Dependency\"]\n",
        "\n",
        "#spacy does not provide the fake ROOT so add a row for the fake Root\n",
        "x.add_row([0,\"ROOT\",0,\"-\"])\n",
        "\n",
        "#parsing reculsively\n",
        "for token in parse:\n",
        "  if token.dep_==\"ROOT\":\n",
        "    x.add_row([token.i+1,token.text,\"0\",token.dep_])\n",
        "  else:  \n",
        "    x.add_row([token.i+1,token.text,token.head.i+1,token.dep_])\n",
        "    \n",
        "\n",
        "\n",
        "print(\"Parsing Result with Spacy API\")\n",
        "#printing the table\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing Result with Spacy API\n",
            "+---------+------------+--------+------------+\n",
            "| TokenID |   Token    | HeadID | Dependency |\n",
            "+---------+------------+--------+------------+\n",
            "|    0    |    ROOT    |   0    |     -      |\n",
            "|    1    |    The     |   2    |    det     |\n",
            "|    2    |   woman    |   3    |   nsubj    |\n",
            "|    3    |   showed   |   0    |    ROOT    |\n",
            "|    4    |     a      |   6    |    det     |\n",
            "|    5    | wellshaped |   6    |    amod    |\n",
            "|    6    |   smile    |   3    |    dobj    |\n",
            "|    7    |     in     |   6    |    prep    |\n",
            "|    8    |    the     |   9    |    det     |\n",
            "|    9    |    dark    |   7    |    pobj    |\n",
            "|    10   |     .      |   3    |   punct    |\n",
            "+---------+------------+--------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IPFBPiKNlvs1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Parsing Visualisation\n",
        "Spacy provides its built-in visualisation suite, [displaCy](https://spacy.io/api/top-level#displacy)"
      ]
    },
    {
      "metadata": {
        "id": "597ayAB7ydNw",
        "colab_type": "code",
        "outputId": "1076cf5c-1ac9-4aec-e031-87beb1096cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "#spaCy comes with a built-in visualization suite\n",
        "from spacy import displacy\n",
        "\n",
        "doc = nlp(sentence)\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance':90})\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"488-0\" class=\"displacy\" width=\"860\" height=\"272.0\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">woman</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">showed</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">wellshaped</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">smile</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">dark.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-488-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-488-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-488-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-488-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-488-0-2\" stroke-width=\"2px\" d=\"M340,137.0 C340,47.0 495.0,47.0 495.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-488-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M340,139.0 L332,127.0 348,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-488-0-3\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-488-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M430,139.0 L422,127.0 438,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-488-0-4\" stroke-width=\"2px\" d=\"M250,137.0 C250,2.0 500.0,2.0 500.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-488-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M500.0,139.0 L508.0,127.0 492.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-488-0-5\" stroke-width=\"2px\" d=\"M520,137.0 C520,92.0 580.0,92.0 580.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-488-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M580.0,139.0 L588.0,127.0 572.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-488-0-6\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-488-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M700,139.0 L692,127.0 708,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-488-0-7\" stroke-width=\"2px\" d=\"M610,137.0 C610,47.0 765.0,47.0 765.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-488-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M765.0,139.0 L773.0,127.0 757.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3107D_pcZ4Ma",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Unfortunately, the parsing result is ***NOT*** perfect. \n",
        "The result shows that *the head of the token '**dark**' is 'in' rather than 'showed'*.\n",
        "\n",
        "\n",
        "### How can we evaluate the parsing result?\n",
        "\n",
        "[Universal Dependencies](http://universaldependencies.org/) is such a grammatical annotation effort. Basiclly, a bunch of linguists sit there to manually label 'which head is this token modifying' or 'which syntactic role is this token playing with respect to which predicate'. We call their annotations ground truth, and evaluate outputs from different systems against this ground truth. The higher accuracy the system achieves, the better this system is."
      ]
    },
    {
      "metadata": {
        "id": "DjhCdUbrdmc_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Parsing Evaluation (with Universal Dependencies)\n",
        "\n",
        "The following code shows the function for evaluating the performance of spaCy parser with Universal Dependencies.\n",
        "\n",
        "\n",
        "*   [CoNLL-U formatted by Universal Dependencies](http://universaldependencies.org/format.html)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DQGM_iDDeE-w",
        "colab_type": "code",
        "outputId": "87b2c8af-0bb5-4b65-9722-0f7838e0679e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "#CoNLL-U Parser parses a CoNLL-U formatted string into a nested python dictionary. \n",
        "!pip install conllu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting conllu\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T3l8nZ--E9tV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's make a function for evaluation the parsing result"
      ]
    },
    {
      "metadata": {
        "id": "DytKlRoEbWzA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import conllu as conllu\n",
        "from conllu import parse\n",
        "\n",
        "#text: the text that you would like to text\n",
        "#gold: the gold-standard annotation for the text\n",
        "def evaluate_sentence_parsing(text, gold):\n",
        "  #parse the text with spacy API\n",
        "  parse = nlp(text)\n",
        "  print(parse)\n",
        "  #setup the table for the parsing result table\n",
        "  x = PrettyTable()\n",
        "  x.field_names = [\"TokenID\", \"Token\", \"HeadID\", \"Dependency\"]\n",
        "  x.add_row([0,\"root\",0,\"-\"])\n",
        "\n",
        "  for token in parse:\n",
        "    if token.dep_==\"ROOT\":\n",
        "      x.add_row([token.i+1,token.text,\"0\",\"root\"])\n",
        "      token.dep_=\"root\"\n",
        "    else:  \n",
        "      x.add_row([token.i+1,token.text,token.head.i+1,token.dep_])\n",
        " \n",
        "  #printing the parsing result\n",
        "  print(\"Parsing Result with Spacy API\")\n",
        "  print(x)\n",
        "  \n",
        "  #setup the table for the parsing result table\n",
        "  y = PrettyTable()\n",
        "  y.field_names = [\"TokenID\", \"Token\", \"HeadID\", \"Dependency\"]\n",
        "  y.add_row([0,\"root\",0,\"-\"])\n",
        "\n",
        "  #parse the gold-standard with conll-u parser \n",
        "  sentences = conllu.parse(gold)\n",
        "  sentence = sentences[0]\n",
        "\n",
        "  for token in sentence:\n",
        "    if token['deprel']==\"root\":\n",
        "      y.add_row([token['id'],token['form'],\"0\",token['deprel']])\n",
        "    else:  \n",
        "      y.add_row([token['id'],token['form'],token['head'],token['deprel']])\n",
        "  print(\"Gold-Standard Annotation\")\n",
        "  print(y)\n",
        "\n",
        "  #summarise the list of predicted head\n",
        "  pred_head = [t.head.i+1 if i != t.head.i else 0 for i, t in enumerate(parse)]\n",
        "  #summarise the list of gold head\n",
        "  gold_head = [token['head'] for i, token in enumerate(sentence)]\n",
        "  \n",
        "  #summarise the list of predicted dependency relations\n",
        "  pred_dep = [t.dep_ for i, t in enumerate(parse)]\n",
        "  #summarise the list of gold dependency relations\n",
        "  gold_dep = [token['deprel'] for i, token in enumerate(sentence)]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print(\"\\n\\nParsing Result vs Gold - Head\")\n",
        "  print(pred_head)\n",
        "  print(gold_head)\n",
        "\n",
        "  print(\"\\n\\nParsing Result vs Gold - Dependency\")\n",
        "  print(pred_dep)\n",
        "  print(gold_dep)\n",
        "  \n",
        "  #performance evaluation - Unlabeled Attachment Score (UAS)\n",
        "  #Unlabeled Attachment Score (UAS): the percent of words that have the correct heads\n",
        "  uas_accuracy = np.sum([1 if g == p else 0 for g, p in zip(gold_head, pred_head)]) / len(gold_head)\n",
        "  \n",
        "  \n",
        "  print(\"\\n\\nUnlabeled Attachment Score (UAS)\")\n",
        "  return uas_accuracy  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwN4Xe8Am38s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With the above function, let's try to test and evaluate it.\n",
        "There are two evaluation metrics:\n",
        "1. ** Unlabeled Attachment Score (UAS)**: the percent of words that have the correct heads\n",
        "2. **Labeled Attachment Score (LAS)**: the percent of words that have the correct heads and labels \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-P2UHiq5c1W7",
        "colab_type": "code",
        "outputId": "1dee31d5-80bb-48d0-fe6d-0873ffa56f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "cell_type": "code",
      "source": [
        "#testing sentence\n",
        "text = \"The woman showed a wellshaped smile in the dark.\"\n",
        "\n",
        "#gold-standard of the sentence\n",
        "gold = \"\"\"\n",
        "# text = The woman showed a wellshaped smile in the dark.\n",
        "1\tThe\tthe\tDET\tDEF\tDefinite=Def|PronType=Art\t2\tdet\t_\t_\n",
        "2\twoman\twoman\tNOUN\tSG-NOM\tNumber=Sing\t3\tnsubj\t_\t_\n",
        "3\tshowed\tshow\tVERB\tPAST\tMood=Ind|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
        "4\ta\ta\tDET\tIND-SG\tDefinite=Ind|PronType=Art\t6\tdet\t_\t_\n",
        "5\twellshaped\twellshaped\tADJ\tPOS\tDegree=Pos\t6\tamod\t_\t_\n",
        "6\tsmile\tsmile\tNOUN\tSG-NOM\tCase=Nom\t3\tobj\t_\t_\n",
        "7\tin\tin\tADP\t_\t_\t9\tprep\t_\t_\n",
        "8\tthe\tthe\tDET\tDEF\tDefinite=Def|PronType=Art\t9\tdet\t_\t_\n",
        "9\tdark\tdark\tADJ\tPOS\tDegree=Pos\t3\tobl\t_\tSpaceAfter=No\n",
        "10\t.\t.\tPUNCT\tPeriod\t_\t3\tpunct\t_\t_\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(evaluate_sentence_parsing(text, gold))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The woman showed a wellshaped smile in the dark.\n",
            "Parsing Result with Spacy API\n",
            "+---------+------------+--------+------------+\n",
            "| TokenID |   Token    | HeadID | Dependency |\n",
            "+---------+------------+--------+------------+\n",
            "|    0    |    root    |   0    |     -      |\n",
            "|    1    |    The     |   2    |    det     |\n",
            "|    2    |   woman    |   3    |   nsubj    |\n",
            "|    3    |   showed   |   0    |    root    |\n",
            "|    4    |     a      |   6    |    det     |\n",
            "|    5    | wellshaped |   6    |    amod    |\n",
            "|    6    |   smile    |   3    |    dobj    |\n",
            "|    7    |     in     |   6    |    prep    |\n",
            "|    8    |    the     |   9    |    det     |\n",
            "|    9    |    dark    |   7    |    pobj    |\n",
            "|    10   |     .      |   3    |   punct    |\n",
            "+---------+------------+--------+------------+\n",
            "Gold-Standard Annotation\n",
            "+---------+------------+--------+------------+\n",
            "| TokenID |   Token    | HeadID | Dependency |\n",
            "+---------+------------+--------+------------+\n",
            "|    0    |    root    |   0    |     -      |\n",
            "|    1    |    The     |   2    |    det     |\n",
            "|    2    |   woman    |   3    |   nsubj    |\n",
            "|    3    |   showed   |   0    |    root    |\n",
            "|    4    |     a      |   6    |    det     |\n",
            "|    5    | wellshaped |   6    |    amod    |\n",
            "|    6    |   smile    |   3    |    obj     |\n",
            "|    7    |     in     |   9    |    prep    |\n",
            "|    8    |    the     |   9    |    det     |\n",
            "|    9    |    dark    |   3    |    obl     |\n",
            "|    10   |     .      |   3    |   punct    |\n",
            "+---------+------------+--------+------------+\n",
            "\n",
            "\n",
            "Parsing Result vs Gold - Head\n",
            "[2, 3, 0, 6, 6, 3, 6, 9, 7, 3]\n",
            "[2, 3, 0, 6, 6, 3, 9, 9, 3, 3]\n",
            "\n",
            "\n",
            "Parsing Result vs Gold - Dependency\n",
            "['det', 'nsubj', 'root', 'det', 'amod', 'dobj', 'prep', 'det', 'pobj', 'punct']\n",
            "['det', 'nsubj', 'root', 'det', 'amod', 'obj', 'prep', 'det', 'obl', 'punct']\n",
            "\n",
            "\n",
            "Unlabeled Attachment Score (UAS)\n",
            "0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xjCHXhT4xY1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "53dd8677-4b47-42ef-fc06-04fb2618beba"
      },
      "cell_type": "code",
      "source": [
        "gold\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# text = The woman showed a wellshaped smile in the dark.\\n1\\tThe\\tthe\\tDET\\tDEF\\tDefinite=Def|PronType=Art\\t2\\tdet\\t_\\t_\\n2\\twoman\\twoman\\tNOUN\\tSG-NOM\\tNumber=Sing\\t3\\tnsubj\\t_\\t_\\n3\\tshowed\\tshow\\tVERB\\tPAST\\tMood=Ind|Tense=Past|VerbForm=Fin\\t0\\troot\\t_\\t_\\n4\\ta\\ta\\tDET\\tIND-SG\\tDefinite=Ind|PronType=Art\\t6\\tdet\\t_\\t_\\n5\\twellshaped\\twellshaped\\tADJ\\tPOS\\tDegree=Pos\\t6\\tamod\\t_\\t_\\n6\\tsmile\\tsmile\\tNOUN\\tSG-NOM\\tCase=Nom\\t3\\tobj\\t_\\t_\\n7\\tin\\tin\\tADP\\t_\\t_\\t9\\tprep\\t_\\t_\\n8\\tthe\\tthe\\tDET\\tDEF\\tDefinite=Def|PronType=Art\\t9\\tdet\\t_\\t_\\n9\\tdark\\tdark\\tADJ\\tPOS\\tDegree=Pos\\t3\\tobl\\t_\\tSpaceAfter=No\\n10\\t.\\t.\\tPUNCT\\tPeriod\\t_\\t3\\tpunct\\t_\\t_\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "f80L6uFlnH5p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Summary\n",
        "The result shows that UAS are 0.8. \n",
        "\n",
        "It means that there are 2 incorrectly predicted head out of 10. \n",
        "1.   The gold head of token 'in' is 'dark', whereas the prediction is 'smile'\n",
        "2.   The gold head of token 'dark' is 'showed', whereas the prediction is 'in'.\n",
        "\n",
        "**UAS** is the percent of words that have the correct heads\n",
        "\n",
        "**LAS** is the percent of words that have the correct heads and labels.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vtPBUrBjeSPt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transition-based Dependency Parser\n",
        "\n",
        "Transition-based Dependency Parser is simple form of greedy discriminative dependency parser. It build only one tree, in one left-to-right seep over the input\n",
        "\n",
        "\n",
        "The transition-based model consists of:\n",
        "*   a ***buffer***, storing unprocessed text, for example, at the every beginning, it stores the input tokens\n",
        "*   a ***stack***, storing elements under-processing, by default, it always has a ROOT node.\n",
        "*   a list of ***depenedency relations***, you can also consider this as the parsing results. it is usually a list of tuples, each of which is a token and its head.\n",
        "\n",
        "The ***arc-standard*** algorithm has three actions which can be applied to change the states of buffer, stack and list:\n",
        "\n",
        "*   **LEFTARC**: assert a head-dependent relation between the word at the top of stack and the word directly beneath it; remove the lower word from the stack. Take the following figure as an example, this will create a (1 -> 2) relation, and 2 will be removed from the stack\n",
        "*   **RIGHTARC**: assert a head-dependent relation between the second word on the stack and the word at the top; remove the word at the top of the stack; Still use the previous figure as example, (2 -> 1) relation will be added to the relation list, and 1 will be removed from the stack.\n",
        "*   **SHIFT**: remove the word from the front of the input buffer and push it onto the stack. Consider the following buffer, the '3' will removed from the buffer \n",
        "\n",
        "####Lecture 7 - slide 48\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1S09VzsLhwwBJadtUmOyrb5_gYRQMsBWs)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "i-n50-MeehIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Parse(object):\n",
        "    def __init__(self, sentence):\n",
        "        self.sentence = sentence\n",
        "        self.stack = [\"<ROOT>\"]\n",
        "        self.buffer = sentence.split()\n",
        "        self.relations = []\n",
        "\n",
        "   #transition setup\n",
        "    def parse_step(self, action):\n",
        "        assert action in [\"SHIFT\", \"LEFTARC\", \"RIGHTARC\"]\n",
        "        if action == \"SHIFT\":\n",
        "            assert len(self.buffer) > 0\n",
        "            token = self.buffer.pop(0)\n",
        "            self.stack.append(token)\n",
        "        else:\n",
        "            assert len(self.stack) >= 2\n",
        "            if action == \"LEFTARC\":\n",
        "                relation = (self.stack[-1], self.stack[-2])\n",
        "                self.relations.append(relation)\n",
        "                self.stack.pop(-2)\n",
        "            else:\n",
        "                relation = (self.stack[-2], self.stack[-1])\n",
        "                self.relations.append(relation)\n",
        "                self.stack.pop(-1)\n",
        "\n",
        "    def parse(self, actions):\n",
        "        print(\"Let's start:\")\n",
        "        output_parse_state(self)\n",
        "        print(\"*\" * 50)\n",
        "        for action in actions:\n",
        "            self.parse_step(action)\n",
        "            print(\"after action:\", action)\n",
        "            output_parse_state(self)\n",
        "            print(\"*\" * 50)\n",
        "\n",
        "\n",
        "def output_parse_state(parse):\n",
        "    print(\"Stack:\", \" \".join(parse.stack))\n",
        "    print(\"Buffer:\", \" \".join(parse.buffer))\n",
        "    print(\"Relations:\")\n",
        "    for relation in parse.relations:\n",
        "        print(\"  %s -> %s\" % (relation[0], relation[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FmYtwXzReh49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence = \"Book me the morning flight\"\n",
        "\n",
        "actions = [\"SHIFT\", \"SHIFT\", \"RIGHTARC\", \"SHIFT\", \"SHIFT\", \"SHIFT\", \"LEFTARC\", \n",
        "           \"LEFTARC\", \"RIGHTARC\", \"RIGHTARC\"]\n",
        "           \n",
        "parse_obj = Parse(sentence)\n",
        "parse_obj.parse(actions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9hrQQZd9Odl9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Discussion\n",
        "Where is this list of actions come from? It looks magic, but how can I know what actions to apply? A classifier is trained to predict what the next action is given the current state.\n",
        "This machine learning classifier takes the state of buffer, stack, previous list of relations as input, and predict what the next action is. \n",
        "\n",
        "For more details, please read*** Lecture 7 from slide 65***"
      ]
    },
    {
      "metadata": {
        "id": "SA5A4eBdcMPJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Exercise\n",
        "Evaluate the spaCy model using Universal Dependencies annotations (You should provide the parsing performance with a metric: UAS)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ncurRJe1lzrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0d5b2c6e-c896-4797-a987-b91d4fbbd7ba"
      },
      "cell_type": "code",
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1vktZbQ_yjvUqTyf0qBhkRsyvDnK0ueMe'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('en_lines-ud-test.conllu')  \n",
        "\n",
        "# If you want to work on your own laptop, you can download the file here: \n",
        "# https://drive.google.com/open?id=1vktZbQ_yjvUqTyf0qBhkRsyvDnK0ueMe"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RgrmQiBng9sw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from io import open\n",
        "from conllu import parse_incr\n",
        "\n",
        "data_file = open(\"en_lines-ud-test.conllu\", \"r\", encoding=\"utf-8\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XftBDrbcDojG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import conllu as conllu\n",
        "from conllu import parse\n",
        "\n",
        "#text: the text that you would like to text\n",
        "#gold: the gold-standard annotation for the text\n",
        "def evaluate_sentence_parsing(text, tokenlist):\n",
        "  #parse the text with spacy API\n",
        "  parse = nlp(text)\n",
        " \n",
        "  #setup the table for the parsing result table\n",
        "  x = PrettyTable()\n",
        "  x.field_names = [\"TokenID\", \"Token\", \"HeadID\", \"Dependency\"]\n",
        "  x.add_row([0,\"root\",0,\"-\"])\n",
        "\n",
        "  for token in parse:\n",
        "    if token.dep_==\"ROOT\":\n",
        "      x.add_row([token.i+1,token.text,\"0\",\"root\"])\n",
        "      token.dep_=\"root\"\n",
        "    else:  \n",
        "      x.add_row([token.i+1,token.text,token.head.i+1,token.dep_])\n",
        " \n",
        "  \n",
        "  #setup the table for the parsing result table\n",
        "  y = PrettyTable()\n",
        "  y.field_names = [\"TokenID\", \"Token\", \"HeadID\", \"Dependency\"]\n",
        "  y.add_row([0,\"root\",0,\"-\"])\n",
        "\n",
        "  #parse the gold-standard with conll-u parser \n",
        "  \n",
        "\n",
        "  for token in tokenlist:\n",
        "    if token['deprel']==\"root\":\n",
        "      y.add_row([token['id'],token['form'],\"0\",token['deprel']])\n",
        "    else:  \n",
        "      y.add_row([token['id'],token['form'],token['head'],token['deprel']])\n",
        " \n",
        "\n",
        "  #summarise the list of predicted head\n",
        "  pred_head = [t.head.i+1 if i != t.head.i else 0 for i, t in enumerate(parse)]\n",
        "  #summarise the list of gold head\n",
        "  gold_head = [token['head'] for i, token in enumerate(tokenlist)]\n",
        "  \n",
        "  #summarise the list of predicted dependency relations\n",
        "  pred_dep = [t.dep_ for i, t in enumerate(parse)]\n",
        "  #summarise the list of gold dependency relations\n",
        "  gold_dep = [token['deprel'] for i, token in enumerate(tokenlist)]\n",
        "  \n",
        "  \n",
        "  #performance evaluation - Unlabeled Attachment Score (UAS)\n",
        "  #Unlabeled Attachment Score (UAS): the percent of words that have the correct heads\n",
        "  uas_accuracy = np.sum([1 if g == p else 0 for g, p in zip(gold_head, pred_head)]) / len(gold_head)\n",
        "  \n",
        "  \n",
        " \n",
        "  return uas_accuracy \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TU3zN2b3REaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#NOTE: you cannot directly call previous evaluate_sentence_parsing function\n",
        "def evaluate_spacy(data_file):\n",
        "  \n",
        "  uas_accuracy =[]\n",
        "  # TODO: write your code here\n",
        "  for sentences in data_file :\n",
        "    \n",
        "    for tokenlist in parse_incr(data_file):\n",
        "     \n",
        "      accuracy=evaluate_sentence_parsing(sentences, tokenlist)\n",
        "      uas_accuracy.append(accuracy)\n",
        "\n",
        "   \n",
        "\n",
        "  print(\"\\n\\nUnlabeled Attachment Score (UAS)\")\n",
        "  return np.mean(uas_accuracy ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_IipC5LWRHGP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evaluate_spacy(data_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FiSCljNLhv3b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Sample Output\n",
        "\n",
        "\n",
        "Spacy Parser Performance Evaluation\n",
        "\n",
        "Unlabeled Attachment Score (UAS)\n",
        "\n",
        "0.87 (This is just a sample score - you need to have your own number)"
      ]
    },
    {
      "metadata": {
        "id": "prRQt1Xro6tB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Dependency Parsing Exercise Answer\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1EpKwn0O3Tw084HYqxAAK8kg_HLZAp1Y5)\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1bjORBrXKZ9rmpDbB_dHYJ11kjKiMxKPA)\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1v6t0nL4vyfGvH-_q860EGWSlGK3JK1cr)\n",
        " "
      ]
    }
  ]
}