{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCHPkKbuhPF6"
   },
   "source": [
    "# Lab 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gV7vMHSahdnf"
   },
   "source": [
    "## Google Drive Access Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTSQtnPkfyzj"
   },
   "outputs": [],
   "source": [
    "# Code to download file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0isQ539cf_nI"
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GNyhgK5QTOuD",
    "outputId": "47418a4b-67da-4596-d6cc-1926655fa4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pprint\n",
    "import re\n",
    "from lxml import etree\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewAbjQzThnT5"
   },
   "source": [
    "### Downloading TED Scripts from Google Drive \n",
    "Click on left side \"Files\" tab and see the file is downloaded successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVk7tjwvhl-6"
   },
   "outputs": [],
   "source": [
    "id = '1B47OiEiG2Lo1jUY6hy_zMmHBxfKQuJ8-'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('ted_en-20160408.xml')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIPpEvI4kqMV"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "VYmEQgB7XoDE",
    "outputId": "926c1949-3c4b-45a0-e9e8-137e2467c3a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along'], ['they', 'continued', 'doing', 'exactly', 'the', 'same']]\n"
     ]
    }
   ],
   "source": [
    "targetXML=open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "\n",
    "# Getting contents of <content> tag from the xml file\n",
    "target_text = etree.parse(targetXML)\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "\n",
    "# Removing \"Sound-effect labels\" using regular expression (i.e. (Audio), (Laughter))\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "\n",
    "# Tokenising the sentence to process it by using NLTK library\n",
    "sent_text=sent_tokenize(content_text)\n",
    "\n",
    "# Removing punctuations and changing all characters to lower case\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "     normalized_text.append(tokens)\n",
    "\n",
    "# Tokenising each sentence to process individual word\n",
    "sentences=[]\n",
    "sentences=[word_tokenize(sentence) for sentence in normalized_text]\n",
    "\n",
    "# Prints only 10 (tokenised) sentences\n",
    "print(sentences[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CojV1MbhkQxK"
   },
   "source": [
    "### Word2Vec - Continuous Bag-Of-Words (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zW1iEee3lZC9"
   },
   "outputs": [],
   "source": [
    "wv_cbow_model = Word2Vec(sentences=sentences, size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "2FKp3X7pkRm6",
    "outputId": "a6088037-91e1-41c8-9495-5ec17055f50d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.844805121421814),\n",
      " ('guy', 0.8092465400695801),\n",
      " ('boy', 0.7867581844329834),\n",
      " ('lady', 0.7734391689300537),\n",
      " ('soldier', 0.7707762122154236),\n",
      " ('gentleman', 0.7431775331497192),\n",
      " ('girl', 0.7310270667076111),\n",
      " ('kid', 0.7269785404205322),\n",
      " ('surgeon', 0.6918785572052002),\n",
      " ('writer', 0.6819698810577393)]\n"
     ]
    }
   ],
   "source": [
    "similar_words=wv_cbow_model.wv.most_similar(\"man\")\n",
    "pprint.pprint(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsFHg0znlPSf"
   },
   "source": [
    "### Word2Vec - Skip Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k16AowhCWUXu"
   },
   "outputs": [],
   "source": [
    "wv_sg_model = Word2Vec(sentences=sentences, size=100, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "e8UiVfr2cBtA",
    "outputId": "2c46b800-80bf-4d42-ecbd-5fd547349d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.7658183574676514),\n",
      " ('guy', 0.7475895285606384),\n",
      " ('boy', 0.7224724292755127),\n",
      " ('soldier', 0.7056839466094971),\n",
      " ('pianist', 0.6882875561714172),\n",
      " ('psychiatrist', 0.683869481086731),\n",
      " ('jr', 0.6833134293556213),\n",
      " ('adage', 0.6786198616027832),\n",
      " ('girl', 0.677717924118042),\n",
      " ('son', 0.6774390935897827)]\n"
     ]
    }
   ],
   "source": [
    "similar_words=wv_sg_model.wv.most_similar(\"man\")\n",
    "pprint.pprint(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfF7YqvpppbG"
   },
   "source": [
    "## Word2Vec vs FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d8IV7D6VAEcr"
   },
   "source": [
    "Word2Vec - Skipgram cannot find similar word \"electrofishing\" as \"electrofishing\" is not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oS9c2uWWquWG",
    "outputId": "15a3c0fb-2702-49dc-cee7-a120f441082d"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a2f7ec57b31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimilar_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwv_sg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"electrofishing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'electrofishing' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "similar_words=wv_sg_model.wv.most_similar(\"electrofishing\")\n",
    "pprint.pprint(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TpkScI8sA9G"
   },
   "source": [
    "### FastText - Skip Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAqOR1Vqps6M"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqkvyiUw_DRh"
   },
   "outputs": [],
   "source": [
    "ft_sg_model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kv26QObJriB7"
   },
   "outputs": [],
   "source": [
    "result=ft_sg_model.wv.most_similar(\"electrofishing\")\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0x2aQpfsFSx"
   },
   "source": [
    "### FastText - Continuous Bag-Of-Words (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUBqvqpc2sbL"
   },
   "outputs": [],
   "source": [
    "ft_cbow_model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUj1RUzM2nLA"
   },
   "outputs": [],
   "source": [
    "result=ft_cbow_model.wv.most_similar(\"electrofishing\")\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hjmOhmRi7Ov"
   },
   "source": [
    "## King - Man + Woman = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xw7b9OSwjGm0"
   },
   "source": [
    "Try both CBOW and Skip Gram model to calculate \"King - Man + Woman = ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ovTXjSdgrw36"
   },
   "outputs": [],
   "source": [
    "result = wv_cbow_model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUtbE2jwq1to"
   },
   "outputs": [],
   "source": [
    "result = wv_sg_model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PWf2I4_WZpG"
   },
   "outputs": [],
   "source": [
    "result = ft_cbow_model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9x51rRhWZrx"
   },
   "outputs": [],
   "source": [
    "result = ft_sg_model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KpAd8t-wjTMA"
   },
   "source": [
    "This is not what we expected...Probably not enough data to answer as \"Queen\"\n",
    "\n",
    "Let's  try with bigger sized data (Google has already trained Word2Vec with Google News data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMY5w8F7rElp"
   },
   "source": [
    "### Google's Pretrained Word2Vec (Google News)\n",
    "[Link to Project](https://code.google.com/archive/p/word2vec/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teQvZDSirVVC"
   },
   "outputs": [],
   "source": [
    "# Beware, this file is big (3.39GB) \n",
    "id2 = '1cOEYOQRd1VXi7ROShhqZbioCcePvgnR5'\n",
    "downloaded = drive.CreateFile({'id':id2}) \n",
    "downloaded.GetContentFile('GoogleNews-vectors-negative300.bin')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_N7kI1WqytK"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64e_sRJ1rhUa"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "gn_wv_model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvMQp2-Tr3zl"
   },
   "outputs": [],
   "source": [
    "result = gn_wv_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWOMy90CXtjy"
   },
   "source": [
    "# Exercise\n",
    "**You need to implement a Lab2 chatbot that returns a duckduckgo search url with the similar words (retrieved by Google's Word2Vec)**\n",
    "**(i.e. https://duckduckgo.com/?q=sydney+hotels+Hotel+motel+boutique_hotel)**\n",
    "\n",
    "\n",
    "1.  Chatbot should start with saying \"Welcome. Where would you like to search?\"\n",
    "2.  When search term (search term must be only one word) is entered by user, chatbot should return a search url with top 4 similar words (retrieved by Google's Word2Vec)\n",
    "3.  After showing a search url, chatbot should ask whether user is satisfied with the result, \"Are you satisfied with this result?\"\n",
    "4.  If user says \"yes\", then system says \"Thank you! See you again\" and system should be shut down.\n",
    "5.  If user says \"no\", then system ask \"Where would you like to search?\" and goes back to process 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Example Communication (Between Lab2 Chatbot and you) \n",
    "\n",
    "\n",
    "```\n",
    "Chatbot: Welcome. What would you like to search?\n",
    "You: hotel\n",
    "Chatbot: https://duckduckgo.com/?q=hotels+Hotel+motel+boutique_hotel\n",
    "Chatbot: Are you satisfied with the result?\n",
    "You: no\n",
    "Chatbot: What would you like to search?\n",
    "You: hospital\n",
    "Chatbot: https://duckduckgo.com/?q=Hospital+hopsital+hosptial+hospitals\n",
    "Chatbot: Are you satisfied with the result?\n",
    "You: yes\n",
    "Chatbot: Thank you! See you again.\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Useful information: [API for Gensim Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ylN0JymXtAw"
   },
   "outputs": [],
   "source": [
    "# You should submit \"ipynb\" file (You can download it from \"File\" > \"Download .ipynb\") to Canvas\n",
    "\n",
    "\n",
    "def response(word):\n",
    "  rob_reponse='Chatbot: https://duckduckgo.com/?q='\n",
    "  rob_reply='Chatbot: Are you satisfied with the result?'\n",
    "  vector=gn_wv_model(word)\n",
    "  result = gn_wv_model.similar_by_vector(vector, topn=4, restrict_vocab=None)\n",
    "  rob_respons=robo_response.join('+'.join(result))\n",
    "  return ({}\\n{}).format(rob_response,robo_reply)\n",
    "\n",
    "flag=True\n",
    "print('Chatbot: Welcome. What would you like to search?')\n",
    "while(flag==True):\n",
    "  user_response=input()\n",
    "  if user_response!='no':\n",
    "    if user_reponse=='yes':\n",
    "      flag=False\n",
    "      print('Chatbot: Thank you! See you again')\n",
    "  else:\n",
    "    flag=False\n",
    "    print('Chatbot: what would you like to search?')\n",
    "    print(response(user_response))\n",
    "    \n",
    "    \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YrjbuZYrXD88"
   },
   "source": [
    "# Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywd_uc5dh2sY"
   },
   "source": [
    "## Word2Vec with Tensorflow\n",
    "\n",
    "If you want to implement Word2Vec with Tensorflow, here is a [sample code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py) by [tensorflow](https://github.com/tensorflow).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UWjBxLdTcEi"
   },
   "source": [
    "## Word Embedding Visual Inspector (WEVI)\n",
    "If you would like to visualise how Word2Vec is learning, the following link is useful https://ronxin.github.io/wevi/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Lab02.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
